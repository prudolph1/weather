{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statements\n",
    "import requests\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from keypass import NOAA_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set api token\n",
    "mytoken = NOAA_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the datetime package to get a year ago today\n",
    "lastyear = datetime.datetime.now()-datetime.timedelta(days=365)\n",
    "\n",
    "#Use the same begin and end date for just one day's data. Format for the API request\n",
    "begin_date = lastyear.strftime(\"%Y-%m-%d\")\n",
    "end_date = lastyear.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "#Location key for the region you are interested in (can be found on NOAA or requested as a different API as well)\n",
    "locationid = 'FIPS:38' #location id for North Dakota\n",
    "datasetid = 'GHCND' #datset id for \"Daily Summaries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url_data = 'https://www.ncdc.noaa.gov/cdo-web/api/v2/data'\n",
    "base_url_stations = 'https://www.ncdc.noaa.gov/cdo-web/api/v2/stations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(locationid, datasetid, begin_date, end_date, mytoken, base_url):\n",
    "    token = {'token': mytoken}\n",
    "\n",
    "    #passing as string instead of dict because NOAA API does not like percent encoding\n",
    "    params = 'datasetid='+str(datasetid)+'&'+'locationid='+str(locationid)+'&'+'startdate='+str(begin_date)+'&'+'enddate='+str(end_date)+'&'+'limit=25'+'&'+'units=standard'\n",
    "    \n",
    "    r = requests.get(base_url, params = params, headers=token)\n",
    "    print(\"Request status code: \"+str(r.status_code))\n",
    "\n",
    "    try:\n",
    "        #results comes in json form. Convert to dataframe\n",
    "        df = pd.DataFrame.from_dict(r.json()['results'])\n",
    "        print(\"Successfully retrieved \"+str(len(df['station'].unique()))+\" stations\")\n",
    "        dates = pd.to_datetime(df['date'])\n",
    "        print(\"Last date retrieved: \"+str(dates.iloc[-1]))\n",
    "\n",
    "        return df\n",
    "\n",
    "    #Catch all exceptions for a bad request or missing data\n",
    "    except:\n",
    "        print(\"Error converting weather data to dataframe. Missing data?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather = get_weather(locationid, datasetid, begin_date, end_date, mytoken, base_url_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_station_info(locationid, datasetid, mytoken, base_url):\n",
    "    token = {'token': mytoken}\n",
    "\n",
    "    #passing as string instead of dict because NOAA API does not like percent encoding\n",
    "    \n",
    "    stations = 'locationid='+str(locationid)+'&'+'datasetid='+str(datasetid)+'&'+'units=standard'+'&'+'limit=1000'\n",
    "    r = requests.get(base_url, headers = token, params=stations)\n",
    "    print(\"Request status code: \"+str(r.status_code))\n",
    "\n",
    "    try:\n",
    "        #results comes in json form. Convert to dataframe\n",
    "        df = pd.DataFrame.from_dict(r.json()['results'])\n",
    "        print(\"Successfully retrieved \"+str(len(df['id'].unique()))+\" stations\")\n",
    "        \n",
    "        if df.count().max() >= 1000:\n",
    "            print('WARNING: Maximum data limit was reached (limit = 1000)')\n",
    "            print('Consider breaking your request into smaller pieces')\n",
    " \n",
    "        return df\n",
    "    #Catch all exceptions for a bad request or missing data\n",
    "    except:\n",
    "        print(\"Error converting station data to dataframe. Missing data?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations = get_station_info(locationid, datasetid, mytoken, base_url_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_weather.merge(df_stations, left_on = 'station', right_on = 'id', how='inner')\n",
    "\n",
    "#Check for missing overlap between station weather info and location info\n",
    "    \n",
    "location_ismissing = df_weather[~df_weather['station'].isin(df_stations['id'])]\n",
    "loc_miss_count = len(location_ismissing['station'].unique())\n",
    "if loc_miss_count != 0:\n",
    "    print(\"Missing location data for \"+str(loc_miss_count)+\" stations\")\n",
    "else:\n",
    "    print(\"Successfully retrieved and combined location data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('id', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['maxdate','mindate'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as flattened csv\n",
    "df.to_csv('weather_'+str(begin_date)+'_noaa.csv', encoding='utf-8', index=False)"
   ]
  }
 ]
}